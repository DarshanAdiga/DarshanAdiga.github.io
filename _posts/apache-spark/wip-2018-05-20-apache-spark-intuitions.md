# Apache Spark - Intuitions
This is *yet another [Apache Spark](https://spark.apache.org/) post* found on the internet. I hope to make it different than most of the existing blogs/posts/tutorials about Apache Spark.

This post will have intuitions and insights about Apache Spark and mostly emphasises the fact that *Apache Spark* is indeed a great tool when it comes to Big Data.

### Target audience
This is write-up is somewhat related to my previous post on [Distributed processing Patterns](apache-spark/distributed-processing-patterns.md), so please go through that post first if you haven't yet.

The most concepts in this post will be helpful for developers who have no or intermediate level of understanding about Apache Spark. Optionaly, a basic understanding of any distributed storage system like [HDFS (Hadoop Distributed File System)](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html) would make this post more helpful.



## Content
- Apache Spark key concepts
- Distributed processing patterns in Apache Spark
- Key points about scalability
- Common pitfalls


## Apache Spark key concepts



 

## Distributed processing patterns in Apache Spark



## Key points about scalability



## Common pitfalls



### References

- https://techvidvan.com/tutorials/features-of-hdfs/